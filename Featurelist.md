Backend
Automatic Question Generation - from Transcript - Done
Transcript generation From Youtube - Done
Basic logging 



Frontend 
Basic UI
Settings window with mode[ollama/Gemini-API] and Model[Modellists] and Question settings, Show defaults other options include Warnings
    Gemini API: Might hit API limit (Using a free API key)
    Ollama : Use the smaller models or Generation takes longer, smaller models may hallucinate 
Defauls: Ollama, gemma3:latest
Add Use gemma:7b for quality output and gemma3:2b for quick output. 
A text window for PDFS [Input: Currently read part From Prev Gen to Current cursor/scroll position]
A Youtube embed for Video based Q Gen [Input: Video url with start time and end time ]


Extras

PPTs (Image Based)
Auth
Adaptive content Detection and question formation Like code, Pictogram data .....